<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>PicToPlate</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"> Megan Huynh, Christine Xu, Mentor: Colin Jemmott</a>
									<ul class="icons">
										<i class="fa fa-github" aria-hidden="true"></i>
										<li><a href="https://github.com/ChristineXu0924/recipe_retrieval/tree/main" class="icon brands fa-github"><span class="label">Github</span></a></li>
										<!-- <li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li>
										<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li> -->
									</ul>
								</header>

							<!-- Banner -->
								<section id="banner">
									<div class="content">
										<header>
											<h1>PicToPlate: <br/>
											From Ingredients to Recipes with Retrieval Augmented Generation</h1>
											<p>UC San Diego Data Science Capstone Project</p>
											<p>Try out the product <a href="https://pic2plate.streamlit.app/">here</a>!</p>
										</header>
										<p>The process of deciding what and how to cook, especially when trying to optimize the use of available ingredients, can be confusing and time-consuming. Our product will address this practical need in everyday life by leveraging the power of object detection and large language models to simplify and enhance the cooking experience for home cooks. Utilizing GPT-4 Vision, our product will allow users to input an image of groceries, create a list of available ingredients, and then search a database of recipes that use those ingredients. Additionally, an AI chatbot will guide users through each step of the process, such as allowing user input for additional ingredients and guiding them through the steps of the recipe. This innovative approach combines computer vision, search, and large language models to enhance the user experience in the kitchen.</p>
										<!-- <ul class="actions">
											<li><a href="#" class="button big">Learn More</a></li>
										</ul> -->
									</div>
									<span class="image object">
										<img src="images/chef_emoji.png" alt="" />
									</span>
								</section>

								<section id="intro">
									<div class="content">
										<header>
											<h2>Introduction<br/></h2>
										</header>
										<p>For those looking to minimize time spent searching for recipes, Google is simply not sufficient. It fails to return succinct results, and does not adequately address search personalization, such as filtering out recipes that include a certain ingredient. In our project, we will utilize object detection models and large language models to enhance recipe search and add assistance throughout the cooking process. 

											Samsung, a major fridge retailer, has been developing fridges that contain internal cameras. These cameras, paired with various artificial intelligence (AI) image classifiers, will recognize what items are stored, create an internal inventory, then create personalized recipe recommendations. Fittingly named ‘smart fridges’ also have the ability to learn about the user, such as how quickly they use an ingredient and are also able to create shopping lists according to the internal inventory. These features are all powered by Samsung Food “the ultimate cooking app for recipe saving, meal planning, grocery shopping, and recipe sharing”. Launched in 2023, the technology has been in development for a few years and has been integrated into their fridges.
											
											As novel as these smart fridges may be, the average consumer may not want to spend thousands of dollars on a new fridge. Creating a free application that will simplify and optimize recipe search will impact a wider range of people.</p>
										<p>We hope to create an interactive application where a user can input pictures of their groceries to communicate with our AI chat bot for guidance in generating cooking recipes ideas and executing the dish. Our project will perform the following steps in data analysis and result production:
											<ol>
												<li>Object detection from a user inputted image</li>
												<li>Search using the list of ingredients returned from the previous step in a database of recipes</li>
												<li>Display possible recipes to cook, involving recipe summarization and further interaction</li>
											  </ol>
										</p>
										<!-- <ul class="actions">
											<li><a href="#" class="button big">Learn More</a></li>
										</ul> -->
									</div>
								</section>

								<section id="methods">
									<div class="content">
										<header>
											<h2>Methods<br/></h2>
										</header>
										<header>
											<h3>Pre-Processing</h3>
										</header>
										<p>
											Aside from merging the datasets as previously mentioned, there was little  data-preprocessing that we implemented. We used a named entity recognition (NER) model to extract the key ingredients from each recipe that cannot be substituted for other ingredients. For example, if the recipe is fettuccine alfredo, parmesan cheese cannot be substituted for cheddar cheese and the type of pasta used should be fettuccine.
										</p>

										<header>
											<h3>Object Detection Model</h3>
										</header>
										<p>
											The model we used to determine individual ingredients in an image is the GPT-4 Vision model. We also tried two open source models, ResNet-50 and YOLO, however, GPT-4 performed significantly better. GPT-4 is able to accurately identify almost every ingredient in the images we have tested. However, a limitation of the model is that it is unable to detect the quantity of ingredients present other than counting. 
										</p>

										<header>
											<h3>Search</h3>
										</header>
										<p>
											We tested 3 different options for our search model: semantic search, TF-IDF, and exact keyword matches, and evaluated them qualitatively. We compared how each search algorithm performed by comparing the ingredients in the recipe returned against our list of input ingredients. From our tests, we found that semantic search made too many assumptions about our inputs, and returned recipes used our ingredients, but also required many other ingredients that were not included in the input. Using \texttt{str.contains()} seemed to have to opposite effect; the recipes returned matched our input, but were extremely simple, often being beverages that only required 2-3 ingredients. TF-IDF was in the middle of the spectrum: the recipes matched our input list, but made some ingredient substitutions. In order to correct for this effect, we employed a NER model to extract key ingredients that must be included in the returned recipes.
										</p>
										<!-- <ul class="actions">
											<li><a href="#" class="button big">Learn More</a></li>
										</ul> -->
									</div>
								</section>

								<section id="results">
									<div class="content">
										<header>
											<h2>Results<br/></h2>
										</header>
										<header>
											<h3>Search Evaluation</h3>
										</header>
										<p>
											Search is inherently hard to evaluate due to two conflicting factors: usefulness and accuracy. To first account for accuracy, we calculated the cosine similarity scores between our ingredient query list and the ingredients utilized in the recipe. However we also felt that it was important to qualitatively examine the results of our search based on if the returned recipe could be feasibly cooked with the ingredients in the query. We will test a number of different ingredient queries, count how many matches there are between the recipe's ingredients and the query's ingredients, and calculate a “feasibility” score. These matches are also subjective on the criteria of with the ingredients in the query, will the final product closely resemble the target recipe? This subjective evaluation allows for ingredient substitution and takes into account common spices or condiments found in a typical kitchen, such as as salt, pepper, sugar, water, and others.
										</p>
										<p>
											We created 4 sample ingredient queries to evaluate our search. Typically, the cosine similarities scores were considerably lower than our feasibility score.
										</p>

										<header>
											<h3>Application</h3>
										</header>
										<p>
											
										</p>
										<!-- <ul class="actions">
											<li><a href="#" class="button big">Learn More</a></li>
										</ul> -->
									</div>
								</section>

								<section id="conclusion">
									<div class="content">
										<header>
											<h2>Conclusion<br/></h2>
										</header>
										<p>

										</p>
										<!-- <ul class="actions">
											<li><a href="#" class="button big">Learn More</a></li>
										</ul> -->
									</div>
								</section>
							</div>
					</div>
				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section> -->

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Navigation</h2>
									</header>
									<ul>
										<li><a href="index.html">HOME</a></li>
										<li><a href="data.html">DATA</a></li>
										<li><a href="methods.html">METHODS</a></li>
										<li><a href="results.html">RESULTS</a></li>
										<li><a href="#">DEMO</a></li>
									</ul>
								</nav>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="#">mlhuynh@ucsd.edu</a></li>
										<li class="icon solid fa-envelope"><a href="#">jix028@ucsd.edu</a></li>
										<li class="icon solid fa-envelope"><a href="#">cjemmott@ucsd.edu</a></li>
									</ul>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; 2024 DSC180B Capstone Final Project: PicToPlate</p>
								</footer>

						</div>
					</div>
							
			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
